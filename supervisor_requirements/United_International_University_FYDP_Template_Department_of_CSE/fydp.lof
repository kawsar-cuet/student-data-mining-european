\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces \textbf {Distribution of Student Outcomes in Dataset.} Pie chart showing the composition of 4,424 students: Graduate (49.9\%, n=2,209), Dropout (32.1\%, n=1,421), Enrolled (17.9\%, n=794). The dataset exhibits moderate class imbalance addressed through stratified sampling and weighted loss functions during model training.}}{2}{figure.1.1}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces \textbf {Feature Ranking Heatmap.} Comparison of five feature ranking methods (Information Gain, Gini Importance, Gain Ratio, etc.) for top 20 features, showing consensus among methods.}}{19}{figure.3.1}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces \textbf {Top 20 Features by Information Gain.} Information gain ranking identifies curricular units approved (both semesters) and tuition fees as top predictors of student outcomes.}}{20}{figure.3.2}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces \textbf {Top 20 Features by Gini Importance.} Gini-based ranking demonstrates consistency with information gain, validating top features.}}{21}{figure.3.3}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces \textbf {Top 20 Features for Dropout Prediction.} Composite importance score from four feature importance methods, identifying features most predictive of dropout risk.}}{22}{figure.3.4}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces \textbf {Comparison of Feature Importance Methods.} Four methods (Tree-based, Permutation, Correlation, Domain Knowledge) applied to dropout prediction, showing method consensus.}}{23}{figure.3.5}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces \textbf {Top 20 Features by Gini Importance.} Bar chart ranking features by Random Forest Gini importance. Semester grades dominate (curricular\_units\_*\_sem\_grade), validating Tinto's academic integration theory. Feature selection retained 46 features explaining $\geq $95\% cumulative importance.}}{24}{figure.3.6}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces \textbf {Top 20 Features by Information Gain.} Entropy-based feature importance ranking. Complementary to Gini importance, demonstrates robust consensus on critical features. Academic variables (success\_rate, average\_grade) and financial indicators (tuition\_fees\_up\_to\_date) emerge as dominant predictors.}}{25}{figure.3.7}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces \textbf {PPN Hyperparameter Tuning Heatmap.} Accuracy variation across learning rates and batch sizes. Optimal configuration (LR=0.001, BS=32) achieves 77.8\% validation accuracy. Heatmap reveals learning rate 0.001 robustly outperforms alternatives across different batch sizes.}}{31}{figure.4.1}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces \textbf {DPN-A Hyperparameter Tuning Heatmap.} Validation accuracy across learning rates and batch sizes. Optimal configuration (LR=0.001, BS=32) achieves 87.05\% accuracy. Demonstrates superior performance and robustness of attention-based architecture.}}{32}{figure.4.2}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces \textbf {HMTL Hyperparameter Tuning Heatmap.} Validation accuracy for multi-task learning configuration. Shows task weighting influence on performance. DPN-A outperforms HMTL, indicating single-task specialization is optimal for this dataset.}}{33}{figure.4.3}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces \textbf {Comprehensive Model Performance Comparison.} Bar chart comparing multiple baseline and proposed models across accuracy, F1-score, and other metrics. Shows Random Forest baseline achieving 79.2\% accuracy, with deep learning models achieving competitive or superior performance.}}{36}{figure.5.1}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces \textbf {Target Class Distribution in Educational Dataset.} Pie chart showing the distribution of student outcomes: Graduate (49.9\%), Dropout (32.1\%), Enrolled (17.9\%). Moderate class imbalance addressed through stratified sampling and weighted loss functions.}}{37}{figure.5.2}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces \textbf {Confusion Matrix for DPN-A (Attention-Based Dropout Prediction).} Binary classification results showing 94.0\% true negative rate (correctly identified not-at-risk students) and 72.3\% true positive rate (correctly identified at-risk students). The model demonstrates strong specificity suitable for early warning systems.}}{39}{figure.5.3}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces \textbf {Confusion Matrices Across All Models.} Comparative visualization showing confusion matrices for Random Forest (baseline), Logistic Regression (baseline), PPN, DPN-A, and HMTL. DPN-A demonstrates the most balanced and accurate predictions across both classes.}}{40}{figure.5.4}%
\contentsline {figure}{\numberline {5.5}{\ignorespaces \textbf {ROC Curves for All Models.} Receiver operating characteristic curves showing area under curve (AUC) for each model. DPN-A achieves 0.910 AUC-ROC, demonstrating excellent discrimination ability between at-risk and not-at-risk students.}}{41}{figure.5.5}%
\contentsline {figure}{\numberline {5.6}{\ignorespaces \textbf {Attention Weight Distribution Across Features.} Bar chart showing normalized attention weights for top 15 features in DPN-A. Semester grades (Tinto academic integration factors) dominate with 68.2\% cumulative importance, validating theoretical framework. Tuition fees and scholarship holder (Bean environmental factors) contribute 31.8\%, demonstrating complementary role of environmental factors.}}{42}{figure.5.6}%
\contentsline {figure}{\numberline {5.7}{\ignorespaces \textbf {SHAP Importance: Random Forest Baseline.} Summary plot showing mean absolute SHAP values for Random Forest features. Establishes baseline for comparison with deep learning models.}}{43}{figure.5.7}%
\contentsline {figure}{\numberline {5.8}{\ignorespaces \textbf {SHAP Importance: Neural Network (DPN-A).} Summary plot showing SHAP values for neural network features. Demonstrates alignment of learned feature importance with attention weights and validates model interpretability.}}{44}{figure.5.8}%
\contentsline {figure}{\numberline {5.9}{\ignorespaces \textbf {Cross-Validation Performance Stability.} Boxplots showing accuracy distribution across 10 folds for PPN and DPN-A. Low variance demonstrates robust generalization and consistent performance across different data splits. DPN-A mean: 86.2\% Â± 1.8\%.}}{45}{figure.5.9}%
\contentsline {figure}{\numberline {5.10}{\ignorespaces \textbf {Training Dynamics of DPN-A.} Plot showing training loss, validation loss, and attention weight evolution across 29 epochs. Demonstrates smooth convergence, early stopping at epoch 18 (best validation), and absence of overfitting. Attention mechanism stabilizes after epoch 10.}}{46}{figure.5.10}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces \textbf {Single Classifier Hyperparameter Tuning.} Accuracy heatmap for Decision Tree and Naive Bayes across all feature selection methods and feature counts, identifying optimal configurations.}}{48}{figure.6.1}%
\contentsline {figure}{\numberline {6.2}{\ignorespaces \textbf {Comprehensive Metrics: Single Classifiers.} Comparison of Accuracy, Precision, Recall, and F1-Score for Decision Tree and Naive Bayes.}}{49}{figure.6.2}%
\contentsline {figure}{\numberline {6.3}{\ignorespaces \textbf {Feature Count Effect: Single Classifiers.} Accuracy trends showing how number of features impacts Decision Tree and Naive Bayes performance.}}{50}{figure.6.3}%
\contentsline {figure}{\numberline {6.4}{\ignorespaces \textbf {Ensemble Methods Feature Selection.} Accuracy heatmap for Random Forest, AdaBoost, and XGBoost across all feature selection methods and configurations.}}{51}{figure.6.4}%
\contentsline {figure}{\numberline {6.5}{\ignorespaces \textbf {Comprehensive Metrics: Ensemble Methods.} Detailed comparison of Accuracy, Precision, Recall, F1-Score, and AUC across ensemble classifiers.}}{52}{figure.6.5}%
\contentsline {figure}{\numberline {6.6}{\ignorespaces \textbf {Feature Count Effect: Ensemble Methods.} Accuracy trends for ensemble methods showing relative robustness to feature count variations.}}{53}{figure.6.6}%
\contentsline {figure}{\numberline {6.7}{\ignorespaces \textbf {Ensemble Methods Comparative Performance.} Direct comparison of Random Forest, AdaBoost, and XGBoost across multiple metrics.}}{54}{figure.6.7}%
\contentsline {figure}{\numberline {6.8}{\ignorespaces \textbf {Neural Network Feature Selection Analysis.} Accuracy heatmap across all feature selection methods and feature counts for standard neural network.}}{55}{figure.6.8}%
\contentsline {figure}{\numberline {6.9}{\ignorespaces \textbf {Comprehensive Metrics: Neural Network.} Performance metrics comparison for neural network across different configurations.}}{56}{figure.6.9}%
\contentsline {figure}{\numberline {6.10}{\ignorespaces \textbf {Feature Count Effect: Neural Network.} Accuracy trends for neural network showing sensitivity to feature dimensionality.}}{57}{figure.6.10}%
\contentsline {figure}{\numberline {6.11}{\ignorespaces \textbf {Deep Learning Attention Model Training History.} Evolution of accuracy, loss, precision, and recall across 200 epochs, demonstrating convergence and model learning.}}{58}{figure.6.11}%
\contentsline {figure}{\numberline {6.12}{\ignorespaces \textbf {Confusion Matrix: Deep Learning Attention (3-Class).} Classification results showing per-class performance for Dropout, Enrolled, and Graduate outcomes.}}{59}{figure.6.12}%
\contentsline {figure}{\numberline {6.13}{\ignorespaces \textbf {Attention Mechanism Feature Importance.} Top 15 features weighted by attention mechanism, showing automatic feature importance discovery.}}{59}{figure.6.13}%
\contentsline {figure}{\numberline {6.14}{\ignorespaces \textbf {SHAP Importance: Decision Tree.} Feature importance based on Shapley values, showing decision tree's feature attribution.}}{60}{figure.6.14}%
\contentsline {figure}{\numberline {6.15}{\ignorespaces \textbf {SHAP Summary Plot: Decision Tree.} Distribution of SHAP values showing positive/negative feature impacts on predictions.}}{60}{figure.6.15}%
\contentsline {figure}{\numberline {6.16}{\ignorespaces \textbf {SHAP Importance: Naive Bayes.} Feature importance analysis for probabilistic classifier.}}{61}{figure.6.16}%
\contentsline {figure}{\numberline {6.17}{\ignorespaces \textbf {SHAP Summary Plot: Naive Bayes.} Shapley-based feature impact analysis for Naive Bayes classifier.}}{62}{figure.6.17}%
\contentsline {figure}{\numberline {6.18}{\ignorespaces \textbf {SHAP Importance: Random Forest.} Feature importance from ensemble tree model, showing collective feature contributions.}}{63}{figure.6.18}%
\contentsline {figure}{\numberline {6.19}{\ignorespaces \textbf {SHAP Summary Plot: Random Forest.} Comprehensive feature impact distribution for ensemble model.}}{64}{figure.6.19}%
\contentsline {figure}{\numberline {6.20}{\ignorespaces \textbf {SHAP Importance: AdaBoost.} Adaptive boosting feature importance analysis.}}{65}{figure.6.20}%
\contentsline {figure}{\numberline {6.21}{\ignorespaces \textbf {SHAP Summary Plot: AdaBoost.} Feature impact distribution for boosted ensemble classifier.}}{66}{figure.6.21}%
\contentsline {figure}{\numberline {6.22}{\ignorespaces \textbf {SHAP Importance: XGBoost.} Extreme gradient boosting feature importance, showing top predictors.}}{67}{figure.6.22}%
\contentsline {figure}{\numberline {6.23}{\ignorespaces \textbf {SHAP Summary Plot: XGBoost.} Feature impact analysis for XGBoost, showing SHAP value distributions.}}{68}{figure.6.23}%
\contentsline {figure}{\numberline {6.24}{\ignorespaces \textbf {SHAP Importance: Neural Network.} Feature importance approximation for deep learning model.}}{69}{figure.6.24}%
\contentsline {figure}{\numberline {6.25}{\ignorespaces \textbf {SHAP Summary Plot: Neural Network.} Feature contribution analysis for neural network predictions.}}{70}{figure.6.25}%
\contentsline {figure}{\numberline {6.26}{\ignorespaces \textbf {Cross-Model Feature Importance Comparison.} SHAP feature importance across all 7 models, showing consensus on key predictors.}}{71}{figure.6.26}%
\contentsline {figure}{\numberline {6.27}{\ignorespaces \textbf {Model Accuracy Comparison from SHAP Analysis.} Comprehensive accuracy comparison showing Deep Learning Attention as top performer.}}{71}{figure.6.27}%
\contentsline {figure}{\numberline {6.28}{\ignorespaces \textbf {Comprehensive Metrics Comparison.} Multi-panel visualization showing (a) Accuracy/Precision/Recall/F1, (b) AUC scores, (c) Cross-validation accuracy, (d) Feature count vs performance trade-offs.}}{72}{figure.6.28}%
\contentsline {figure}{\numberline {6.29}{\ignorespaces \textbf {Confusion Matrices: All Models.} Side-by-side comparison of confusion matrices showing true vs predicted labels for all 6 models across three classes (Dropout, Enrolled, Graduate).}}{73}{figure.6.29}%
\contentsline {figure}{\numberline {6.30}{\ignorespaces \textbf {ROC Curves: All Models.} Receiver Operating Characteristic curves for all models showing per-class and micro-average AUC scores for three-class classification.}}{73}{figure.6.30}%
\contentsline {figure}{\numberline {6.31}{\ignorespaces \textbf {10-Fold Cross-Validation Results.} Distribution of validation scores across 10 folds: (a) Boxplots showing score ranges, (b) Mean accuracy with confidence intervals.}}{74}{figure.6.31}%
\contentsline {figure}{\numberline {6.32}{\ignorespaces \textbf {Comprehensive Model Evaluation Summary.} Master comparison table integrating all evaluation metrics, feature counts, and key performance indicators.}}{74}{figure.6.32}%
\addvspace {10\p@ }
